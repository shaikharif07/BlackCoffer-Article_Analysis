{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f32f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textblob\n",
    "# !pip install textstat\n",
    "# !pip install --upgrade textstat\n",
    "# !pip uninstall textstat\n",
    "# !pip install html5lib\n",
    "# !pip install textstat==0.7.0\n",
    "import requests                           #for making HTTP requests \n",
    "import openpyxl                           #for reading Excel files\n",
    "from bs4 import BeautifulSoup             #for parsing HTML content\n",
    "import numpy as np\n",
    "import pandas as pd                       #for data manipulation and analysis\n",
    "import regex as re                        #for regular expressions\n",
    "import os                                 \n",
    "import nltk                               # for natural language processing\n",
    "# nltk.download('punkt')\n",
    "from textblob import TextBlob             #for text sentiment analysis\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import textstat                            #for text statistics\n",
    "from textstat.textstat import textstatistics,legacy_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb1448d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ittrace over all rows of excel file and pass url to fun\n",
    "# the function takes url and extracts the content \n",
    "\n",
    "def extract_article(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content.decode(\"utf-8\"), \"html.parser\")\n",
    "    title = soup.find(\"title\").get_text(strip=True)\n",
    "    paragraphs = soup.find_all(\"p\", class_=None, id=None, style=None)\n",
    "    paragraphs = [re.sub('<[^<]+?>', '', str(p)) for p in paragraphs]\n",
    "    article_text = \"\\n\".join(paragraphs)\n",
    "    with open(f\"{url_id}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{title}\\n{article_text}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = 'C:\\\\Users\\\\arif shaikh\\\\Downloads\\\\Input.xlsx'\n",
    "    wb_obj = openpyxl.load_workbook(path)\n",
    "    sheet_obj = wb_obj.active\n",
    "    max_row = sheet_obj.max_row\n",
    "\n",
    "    for i in range(2, max_row + 1):\n",
    "        url_id = sheet_obj.cell(row=i, column=1).value\n",
    "        cell_obj = sheet_obj.cell(row=i, column=2)\n",
    "        url = cell_obj.value\n",
    "        extract_article(url)\n",
    "        \n",
    "    wb_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60a495cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arif shaikh\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13f8502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# readline of all textfiles(line 1 is treated as title) \n",
    "# and store it to a list and later convert to dataframe with columns title and article \n",
    "\n",
    "folder_path = 'C:\\\\Users\\\\arif shaikh\\\\'\n",
    "data = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.readlines()\n",
    "            if len(content) >= 2:\n",
    "                title = content[0].strip()\n",
    "                article = ' '.join(content[1:]).strip()\n",
    "                data.append((title, article))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Title', 'Article'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c49b2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace , by whitespace\n",
    "df['Article']=df['Article'].str.replace(',','')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ba23609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Coronavirus impact on energy markets | Blackco...</td>\n",
       "      <td>The coronavirus also known as COVID-19 is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>COVID-19 Impact on Hospitality Industry | Blac...</td>\n",
       "      <td>In December 2019 a novel coronavirus strain (S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Lessons from the past: Some key learnings rele...</td>\n",
       "      <td>As a race we are not ready for any kind of cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Estimating the impact of COVID-19 on the world...</td>\n",
       "      <td>COVID-19 an unprecedented pandemic for us but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td></td>\n",
       "      <td>greeley\\n cuellar\\n unfortunately\\n guerin\\n c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "107  Coronavirus impact on energy markets | Blackco...   \n",
       "108  COVID-19 Impact on Hospitality Industry | Blac...   \n",
       "109  Lessons from the past: Some key learnings rele...   \n",
       "110  Estimating the impact of COVID-19 on the world...   \n",
       "111                                                      \n",
       "\n",
       "                                               Article  \n",
       "107  The coronavirus also known as COVID-19 is not ...  \n",
       "108  In December 2019 a novel coronavirus strain (S...  \n",
       "109  As a race we are not ready for any kind of cri...  \n",
       "110  COVID-19 an unprecedented pandemic for us but ...  \n",
       "111  greeley\\n cuellar\\n unfortunately\\n guerin\\n c...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a8e035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined stop words saved to combined_stopwords.txt.\n"
     ]
    }
   ],
   "source": [
    "# since there are multiple stopfiles well combine them together\n",
    "\n",
    "Stop_folder = r'C:\\Users\\arif shaikh\\Downloads\\Stop_folder\\\\'  \n",
    "output_file = 'combined_stopwords.txt'  \n",
    "\n",
    "combined_stop_words = set()  #to avoid duplicates\n",
    "\n",
    "for filename in os.listdir(Stop_folder):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(Stop_folder, filename)\n",
    "        with open(file_path, 'r', encoding='latin-1') as file:\n",
    "            stop_words = file.read().lower().split('\\n')\n",
    "            combined_stop_words.update(stop_words)\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(combined_stop_words))\n",
    "\n",
    "print(f\"Combined stop words saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5347e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordsFile =r'C:\\Users\\arif shaikh\\combined_stopwords.txt'\n",
    "positiveWordsFile ='C:\\\\Users\\\\arif shaikh\\\\Downloads\\\\positive-words.txt'\n",
    "nagitiveWordsFile ='C:\\\\Users\\\\arif shaikh\\\\Downloads\\\\negative-words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8603c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out words whivh are not in stopwords\n",
    "\n",
    "with open(stopWordsFile ,'r') as stop_words:\n",
    "    stopWords = stop_words.read().lower()\n",
    "    stopWordList = stopWords.split('\\n')\n",
    "    stopWordList[-1:] = []            #removes the last element(mostly emptyspace)\n",
    "    \n",
    "def tokenizer(text):\n",
    "    text = text.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') #RegexpTokenizer object that tokenizes the text based on expression\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_words = list(filter(lambda token: token not in stopWordList, tokens))\n",
    "    return filtered_words  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0266e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(positiveWordsFile,'r') as posfile:\n",
    "    positivewords=posfile.read().lower()\n",
    "    positiveWordList=positivewords.split('\\n')\n",
    "\n",
    "def positive_score(text):\n",
    "    PosWords = 0\n",
    "    rawToken = tokenizer(text)\n",
    "    for word in rawToken:\n",
    "        if word in positiveWordList:\n",
    "            PosWords  += 1\n",
    "    \n",
    "    sumPos = PosWords\n",
    "    return sumPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "68456170",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(nagitiveWordsFile ,'r') as negfile:\n",
    "    negativeword=negfile.read().lower()\n",
    "    negativeWordList=negativeword.split('\\n')\n",
    "    \n",
    "def negative_score(text):\n",
    "    NegWords=0\n",
    "    rawToken = tokenizer(text)\n",
    "    for word in rawToken:\n",
    "        if word in negativeWordList:\n",
    "            NegWords -=1\n",
    "    sumNeg = NegWords \n",
    "    sumNeg = sumNeg * -1\n",
    "    return sumNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f00f65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"positive_score\"] = df[\"Article\"].apply(positive_score)\n",
    "df[\"negative_score\"] = df[\"Article\"].apply(negative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e67c0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = []\n",
    "\n",
    "for i in df[\"Article\"]:\n",
    "    polarity.append(TextBlob(i).sentiment.polarity)\n",
    "\n",
    "df[\"polarity_score\"] = polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f822380",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity = []\n",
    "\n",
    "for i in df[\"Article\"]:\n",
    "    subjectivity.append(TextBlob(i).sentiment.subjectivity)\n",
    "    \n",
    "df[\"subjectivity_score\"] = subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0acd0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sentence_length(text):\n",
    "    sentence_list = sent_tokenize(text)\n",
    "    tokens = tokenizer(text)\n",
    "    totalWordCount = len(tokens)\n",
    "    totalSentences = len(sentence_list)\n",
    "    average_sent = 0\n",
    "    if totalSentences != 0:\n",
    "        average_sent = totalWordCount / totalSentences\n",
    "    \n",
    "    average_sent_length= average_sent\n",
    "    \n",
    "    return round(average_sent_length)\n",
    "\n",
    "df[\"Average sentence length\"] = df[\"Article\"].apply(average_sentence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a40609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  difficult or advanced words in terms of their linguistic complexity\n",
    "# if it has more than two vowels and does not end with 'es' or 'ed'.\n",
    "\n",
    "def percentage_complex_word(text):\n",
    "    tokens = tokenizer(text)\n",
    "    complexWord = 0\n",
    "    complex_word_percentage = 0\n",
    "    \n",
    "    for word in tokens:\n",
    "        vowels=0\n",
    "        if word.endswith(('es','ed')):\n",
    "            pass\n",
    "        else:\n",
    "            for w in word:\n",
    "                if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
    "                    vowels += 1\n",
    "            if(vowels > 2):\n",
    "                complexWord += 1\n",
    "    if len(tokens) != 0:\n",
    "        complex_word_percentage = complexWord/len(tokens)\n",
    "    \n",
    "    return complex_word_percentage\n",
    "\n",
    "df[\"Percentage complex words\"] = df[\"Article\"].apply(percentage_complex_word)\n",
    "df[\"Percentage complex words\"] = df[\"Percentage complex words\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "279b46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure of readability or textual complexity\n",
    "def fog_index(average_sentence_length, percentage_complex_word):\n",
    "    fogIndex = 0.4 * (average_sentence_length + percentage_complex_word)\n",
    "    return fogIndex\n",
    "\n",
    "df[\"Fog index\"] = np.vectorize(fog_index)(df['Average sentence length'],df['Percentage complex words'])\n",
    "# element-wise to the corresponding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ce21360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_wordper_sent(text):\n",
    "    sentence_list = sent_tokenize(text)\n",
    "    tokens = tokenizer(text)\n",
    "    totalWord = len(tokens)\n",
    "    totalSent = len(sentence_list)\n",
    "    if totalSent != 0:\n",
    "        average_word_sent = totalWord / totalSent\n",
    "    \n",
    "    return round(average_word_sent)\n",
    "\n",
    "df[\"Avg words per sentence\"] = df[\"Article\"].apply(average_wordper_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1fa7edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_word_count(text):\n",
    "    tokens = tokenizer(text)\n",
    "    complexWord = 0\n",
    "    \n",
    "    for word in tokens:\n",
    "        vowels=0\n",
    "        if word.endswith(('es','ed')):    #non complex\n",
    "            pass\n",
    "        else:\n",
    "            for w in word:\n",
    "                if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
    "                    vowels += 1\n",
    "            if(vowels > 2):\n",
    "                complexWord += 1\n",
    "    return complexWord\n",
    "\n",
    "df[\"Complex word count\"] = df[\"Article\"].apply(complex_word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "46c21c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def word_count(text):\n",
    "    tokens = tokenizer(text)\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    return len(tokens)\n",
    "\n",
    "df[\"Word Count\"] = df[\"Article\"].apply(word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "43c45be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllables(word):\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    syllable_count = 0\n",
    "    \n",
    "    if word.endswith(('es', 'ed')):\n",
    "        word = word[:-2]\n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        if word[i] in vowels and (i == 0 or word[i-1] not in vowels):\n",
    "            syllable_count += 1\n",
    "    \n",
    "    return syllable_count\n",
    "\n",
    "def syllables_per_word(text):\n",
    "    tokens = tokenizer(text)\n",
    "    word_count = len(tokens)\n",
    "    \n",
    "    total_syllables = sum(syllables(word) for word in tokens)\n",
    "    SPW = total_syllables / word_count\n",
    "    \n",
    "    return round(SPW, 1)\n",
    "\n",
    "df[\"Syllable per word\"] = df[\"Article\"].apply(lambda x: syllables_per_word(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ac8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b296d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronouns(text):\n",
    "    count = 0\n",
    "    pronoun_list = ['I', 'we', 'my', 'ours', 'us', 'We', 'My', 'Ours', 'Us']\n",
    "    for word in re.findall(r'\\b\\w+\\b', text):\n",
    "        if word in pronoun_list:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "df[\"Personal pronoun\"] = df[\"Article\"].apply(pronouns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab3d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d21e0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_len(text):\n",
    "    char_list = textstat.char_count(text, ignore_spaces=True)\n",
    "    tokens = tokenizer(text)\n",
    "    totalWord = len(tokens)\n",
    "    totalchar = (char_list)\n",
    "    if totalWord!= 0:\n",
    "        avg_char = totalchar / totalWord\n",
    "    \n",
    "    return round(avg_char)\n",
    "\n",
    "df[\"Average word length\"] = df['Article'].apply(avg_word_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b216c539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3      40  https://insights.blackcoffer.com/will-machine-...\n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des = r'C:\\Users\\arif shaikh\\Downloads\\Input.xlsx'\n",
    "df1 = pd.read_excel(des)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "00dc8bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Article</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>Average sentence length</th>\n",
       "      <th>Percentage complex words</th>\n",
       "      <th>Avg words per sentence</th>\n",
       "      <th>Complex word count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Syllable per word</th>\n",
       "      <th>Personal pronoun</th>\n",
       "      <th>Average word length</th>\n",
       "      <th>Fog index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>Estimating the impact of COVID-19 on the world...</td>\n",
       "      <td>Will COVID19 END Globalization?\\n Globalizatio...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.078863</td>\n",
       "      <td>0.330512</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.364063</td>\n",
       "      <td>11.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.545625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>Travel and Tourism Outlook | Blackcoffer Insights</td>\n",
       "      <td>The UN projects a 20-30% decline in internatio...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.273255</td>\n",
       "      <td>0.424912</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.931343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>Gaming Disorder and Effects of Gaming on Healt...</td>\n",
       "      <td>Perhaps the virtual illusion has become today’...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.061629</td>\n",
       "      <td>0.433699</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>8.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.343158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>What is the repercussion of the environment du...</td>\n",
       "      <td>What is COVID 19 pandemic?\\n On 31st December ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.059480</td>\n",
       "      <td>0.405852</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.331169</td>\n",
       "      <td>9.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.732468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>Due to the COVID-19 the repercussion of the en...</td>\n",
       "      <td>Epidemics in general have both direct and indi...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.057154</td>\n",
       "      <td>0.391464</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.388686</td>\n",
       "      <td>11.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.555474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Estimating the impact of COVID-19 on the world...   \n",
       "1  Travel and Tourism Outlook | Blackcoffer Insights   \n",
       "2  Gaming Disorder and Effects of Gaming on Healt...   \n",
       "3  What is the repercussion of the environment du...   \n",
       "4  Due to the COVID-19 the repercussion of the en...   \n",
       "\n",
       "                                             Article  positive_score  \\\n",
       "0  Will COVID19 END Globalization?\\n Globalizatio...            21.0   \n",
       "1  The UN projects a 20-30% decline in internatio...             3.0   \n",
       "2  Perhaps the virtual illusion has become today’...            24.0   \n",
       "3  What is COVID 19 pandemic?\\n On 31st December ...             6.0   \n",
       "4  Epidemics in general have both direct and indi...            25.0   \n",
       "\n",
       "   negative_score  polarity_score  subjectivity_score  \\\n",
       "0            42.0        0.078863            0.330512   \n",
       "1             3.0        0.273255            0.424912   \n",
       "2            42.0        0.061629            0.433699   \n",
       "3            24.0        0.059480            0.405852   \n",
       "4            54.0        0.057154            0.391464   \n",
       "\n",
       "   Average sentence length  Percentage complex words  Avg words per sentence  \\\n",
       "0                     11.0                  0.364063                    11.0   \n",
       "1                      7.0                  0.328358                     7.0   \n",
       "2                      8.0                  0.357895                     8.0   \n",
       "3                      9.0                  0.331169                     9.0   \n",
       "4                     11.0                  0.388686                    11.0   \n",
       "\n",
       "   Complex word count  Word Count  Syllable per word  Personal pronoun  \\\n",
       "0               233.0       640.0                2.1               3.0   \n",
       "1                22.0        67.0                1.9               2.0   \n",
       "2               170.0       475.0                2.1              13.0   \n",
       "3               102.0       308.0                2.0               4.0   \n",
       "4               213.0       548.0                2.3               2.0   \n",
       "\n",
       "   Average word length  Fog index  \n",
       "0                 10.0   4.545625  \n",
       "1                 13.0   2.931343  \n",
       "2                 11.0   3.343158  \n",
       "3                 10.0   3.732468  \n",
       "4                 11.0   4.555474  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_df = pd.concat([df1,df],axis = 1)\n",
    "fin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa50bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del fin_df[\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16fc2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "del fin_df[\"Article\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b275a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>Average sentence length</th>\n",
       "      <th>Percentage complex words</th>\n",
       "      <th>Avg words per sentence</th>\n",
       "      <th>Complex word count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Syllable per word</th>\n",
       "      <th>Personal pronoun</th>\n",
       "      <th>Average word length</th>\n",
       "      <th>Fog index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.078863</td>\n",
       "      <td>0.330512</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.364063</td>\n",
       "      <td>11.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.545625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.273255</td>\n",
       "      <td>0.424912</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.931343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.061629</td>\n",
       "      <td>0.433699</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>8.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.343158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.059480</td>\n",
       "      <td>0.405852</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.331169</td>\n",
       "      <td>9.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.732468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.057154</td>\n",
       "      <td>0.391464</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.388686</td>\n",
       "      <td>11.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.555474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  positive_score  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...            21.0   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...             3.0   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...            24.0   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...             6.0   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...            25.0   \n",
       "\n",
       "   negative_score  polarity_score  subjectivity_score  \\\n",
       "0            42.0        0.078863            0.330512   \n",
       "1             3.0        0.273255            0.424912   \n",
       "2            42.0        0.061629            0.433699   \n",
       "3            24.0        0.059480            0.405852   \n",
       "4            54.0        0.057154            0.391464   \n",
       "\n",
       "   Average sentence length  Percentage complex words  Avg words per sentence  \\\n",
       "0                     11.0                  0.364063                    11.0   \n",
       "1                      7.0                  0.328358                     7.0   \n",
       "2                      8.0                  0.357895                     8.0   \n",
       "3                      9.0                  0.331169                     9.0   \n",
       "4                     11.0                  0.388686                    11.0   \n",
       "\n",
       "   Complex word count  Word Count  Syllable per word  Personal pronoun  \\\n",
       "0               233.0       640.0                2.1               3.0   \n",
       "1                22.0        67.0                1.9               2.0   \n",
       "2               170.0       475.0                2.1              13.0   \n",
       "3               102.0       308.0                2.0               4.0   \n",
       "4               213.0       548.0                2.3               2.0   \n",
       "\n",
       "   Average word length  Fog index  \n",
       "0                 10.0   4.545625  \n",
       "1                 13.0   2.931343  \n",
       "2                 11.0   3.343158  \n",
       "3                 10.0   3.732468  \n",
       "4                 11.0   4.555474  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "341f224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df.to_csv('TextAnalysisOutput1.csv',index = None)\n",
    "# TextAnalysisOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673315a2",
   "metadata": {},
   "source": [
    "Thanks a lot Black Coffere for your time and effort in organizing this task. It has been a great experience and I look forward to applying the skills I have learned to future projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
